\documentclass[../main.tex]{subfile}
\graphicspath{{\subfix{../images}}}
\begin{document}
在训练中对于每一层，由于它之前层的参数会变化，所以它的输入的分布也会变化，这导致训练深度神经网络十分复杂。这个现象通过要求更低的学习率以及精心的参数初始化，降低了训练速度，并使得训练使用饱和非线性的模型非常困难。我们将这个现象成为\textit{内部协变量偏移}，并通过归一化每一层的输入来解决它。我们的方法从将归一化作为模型结构的一部分汲取力量并对\textit{每一个训练迷你批}进行归一化。批归一化使得我们可以使用更大的学习率并不用那么关心初始化。它也可以减少过拟合，在某些情况下消除了对于Dropout的需要。将批归一化应用在最好的图像分类模型上，模型达到与原来相同准确率的时间减少了14倍，并最终以很大幅度击败了原有模型。使用集成的进行了批归一化的网络，我们进一步提高了最好的ImageNet分类结果：到达了4.9\%的top-5验证错误率（以及4.8\%的测试错误率），超过了人类的准确率。
\end{document}