\documentclass[../main.tex]{subfile}

\begin{document}

当主机到GPU备份来自固定（页锁定）内存时，它们的速度要快得多。关于何时以及如何使用固定内存的更多细节，见\href{https://pytorch.org/docs/stable/notes/cuda.html#cuda-memory-pinning}{使用固定内存缓存}。

对于数据加载，将\lstinline{DataLoader}设置为\lstinline{pin_memory=True}会自动将抓取的数据张量放在固定内存，因此使得到CUDA使能的GPU数据传输更快。

默认的内存固定逻辑仅仅识别张量和包含张量的映射以及iteralbe。在默认情况下，如果固定逻辑发现一个自定义类型的批（当你使用返回自定义批类型的\lstinline{collate_fn}时），或者如果批的每一个元素都是自定义类型，固定逻辑不会识别它们，并会在不固定内存的情况下返回批（或者哪些元素）。为了使能对于自定义批的内存固定，在你的自定义类型上定义\lstinline{pin_memory()}方法。

见下面的例子。

\begin{lstlisting}[language=Python]
class SimpleCustomBatch:
    def __init__(self, data):
        transposed_data = list(zip(*data))
        self.inp = torch.stack(transposed_data[0], 0)
        self.tgt = torch.stack(transposed_data[1], 0)
    
    # 在自定义类型上的自定义固定内存方法
    def pin_memory(self):
        self.inp = self.inp.pin_memory()
        self.tgt = self.tgt.pin_memory()
        return self
    
def collate_wrapper(batch):
    return SimpleCustomBatch(batch)

inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)
tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)
dataset = TensorDataset(inps, tgts)

loader = DataLoader(dataset, 
                    batch_size=2, 
                    collate_fn=collate_wrapper, 
                    pin_memory=Treu
                    )

for batch_ndx, sample in enumerate(loader):
    print(sample.inp.is_pinned())
    print(sample.tgt.is_pinned())
\end{lstlisting}

\end{document}