\documentclass[../main.tex]{subfile}
\graphicspath{{\subfix{../images}}}
\begin{document}

有两个设计选择值得进一步讨论。第一个是：为什么在微调CNN和训练物体检测SVM的过程中，对正反例子的定义不同？简要回顾一下定义，对于微调，我们将每个候选物体映射到与之有最大IoU重叠的ground-truth实例（如果有的话），如果IoU至少为0.5，则将其标记为匹配ground-truth类的正例。所有其他候选都被标记为 "背景"（即所有类别的负例）。相比之下，在训练SVM时，我们只把ground-truth框作为其各自类别的正例，并把与对应类别的所有实例重合度低于0.3 IoU的候选标记为该类别的负例。属于灰色区域的候选（IoU超过0.3的重叠，但不属于ground-truth）将被忽略。

从历史上看，我们之所以得出这些定义，是因为我们一开始就在ImageNet预训练的CNN计算的特征上训练SVM，所以微调在当时并不是一个考虑因素。在那个设置中，我们发现我们训练SVM的特定标签定义在我们评估的选项集（包括我们现在用于微调的设置）中是最佳的。当我们开始使用微调时，我们最初使用了与SVM训练相同的正负样例定义。然而，我们发现，结果比使用我们目前的正负定义所得到的结果要差得多。

我们的假设是，在如何定义正例和负例方面的这种差异，从根本上说并不重要，而是源于微调数据有限的事实。我们目前的方案引入了许多 "抖动 "的例子（那些重合度在0.5和1之间但不是ground truth的候选），这使得正例的数量扩大了大约30倍。我们猜想，在对整个网络进行微调时，需要这个大集合以避免过度拟合。然而，我们也注意到，使用这些抖动的例子很可能是次优的，因为网络不是为了精确定位而被微调的。

这就导致了第二个问题。为什么在微调之后还要训练SVM？简单地应用微调网络的最后一层，也就是一个21路softmax回归分类器，作为物体检测器会更干净。我们尝试了这个方法，发现VOC 2007的性能从54.2\%下降到50.9\% mAP。这种性能下降可能是由几个因素共同造成的，包括在微调中使用的正例定义并不强调精确的定位，而且softmax分类器是在随机抽样的负例上训练的，而不是在用于SVM训练的 “难负例”子集上训练的。

这一结果表明，在微调后不训练SVM也能获得接近相同水平的性能。我们猜想，通过对微调的一些额外调整，性能差距可能会被缩小。如果是真的，这将简化和加快R-CNN的训练，而在检测性能上没有损失。

\end{document}