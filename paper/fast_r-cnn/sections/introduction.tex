\documentclass[../main]{subfile}
\graphicspath{\subfix{../images}}

\begin{document}

近来，深度卷积网络显著提高了图片分类和物体检测的准确率。与图片分类相比，物体检测是一个更具挑战性的任务，为了求解它要求更加复杂的方法。由于它的复杂性，近来的方法训练多阶段流水线模型，这既缓慢又不优雅。

由于检测对于精确的物体定位的要求导致的复杂性，创造了两个首要的挑战。首先，必须处理大量候选物体位置（经常被称为“候选位置”）。其次，这些候选位置仅仅提供了粗略的位置，必须通过从新调整来得到精细的位置。解决这些问题的办法通常会在速度、准确率或简便性上折中。

在这片文章中，我们优化了基于卷积网络的sota物体检测器的训练过程。我们提出了一种可以同时学习分类物体候选并调整它们的空间位置的单一阶段训练算法。

最终的方法在训练很深的检测网络（VGG16\cite{vgg}）时比R-CNN\cite{rcnn}快9倍，比SPPnet\cite{spp}快3倍。在运行时，检测器网络处理每张图片的时间为0.3秒（不包括候选位置生成时间），同时在PASCAL VOV 2012上达到了66\%的准确率（R-CNN的准确率为62\%）。

\subsection{R-CNN和SPPnet}

基于区域的卷积网络方法（R-CNN）\cite{rcnn}通过使用深度卷积网络来为候选物体分类达到了很好的物体检测准确率。然而，R-CNN有显著缺点：
\begin{enumerate}
    \item \textbf{训练是一个多阶段流水线。}R-CNN首先使用对数损失在候选物体上微调卷积网络。之后，它使用支持向量机（SVM）拟合卷积特征。哪些SVM作为物体检测器，取代了通过微调习得的softmax分类器。在第三个训练阶段，学习得到了边界框回归器。
    \item \textbf{训练在空间和时间上十分昂贵。}为了训练SVM和边界框回归器，需要从每张图片的每个物体候选提取特征并写入磁盘。在很深的网络中，例如VGG16，为了VOC07 trainval集合的5k张图片，这个过程需要2.5个GPU日。这些特征要求数百G来存储。
    \item \textbf{物体检测很慢。}在测试时，需要从每张测试图片的每个候选物体提取特征。使用VGG16进行检测，在GPU上处理一张图片的时间为47秒。
\end{enumerate}

R-CNN之所以慢是因为它在没有共享计算的情况下，为每一个候选物体进行了一次卷积网络的前向传播。空间金字塔池化网络（SPPnets）\cite{spp}通过共享计算提高了R-CNN的速度。SPPnet方法为整个输入图片计算了卷积特征图，之后通过从共享特征图中提取的特征向量来为每个物体候选分类。通过对特征图中候选位置内的部分进行最大池化并得到一个固定大小的输出（例如，$6\times 6$）来为候选区域提取特征。池化得到多个输出尺寸之后像空间金字塔池化\cite{sp}一样将它们连接。SPPnet在测试阶段为R-CNN加速了10到100倍。训练时间也由于更快的候选位置特征提取减少了3倍时间。

然而SPPnet也有显著的缺陷。类似R-CNN，训练是一个多阶段流水面，包括特征提取、使用对数损失微调网络、训练SVM和最后的拟合边界框回归器。特征也被写入磁盘。但是不同于R-CNN，\cite{spp}中提出的微调算法不能更新在空间金字塔池化前的卷积层。毫不意外地，这个局限（固定的卷积层）限制了很深的网络的准确率。

\subsection{贡献}

我们提出了一个新的弥补了R-CNN和SPPnet缺陷的新训练算法，同时提高了它们的速度和准确率。由于相比起来更快的训练和测试，我们将这种方法成为\textit{Fast R-CNN}。Fast R-CNN方法有如下优势：
\begin{enumerate}
    \item 比R-CNN和SPPnet更高的检测质量（mAP）
    \item 单阶段，使用多任务损失的训练
    \item 可以更新网络所有层的训练
    \item 特征缓存不需要磁盘存储
\end{enumerate}

Fast R-CNN使用Python和C++（Caffe）编写，并在MIT执照下开源，见\href{https://github.com/rbgirshick/fast-rcnn}{https://github.com/rbgirshick/fast-rcnn}。
\end{document}